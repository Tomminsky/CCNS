{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Cognitive Neuroscience Practical Assignment 4\n",
    "## fMRI-based stimulus prediction using generative models\n",
    "### Tommy Clausner (s4836219) and Steven Smits (s4237263)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data and preprocessing\n",
    "[Make sure to have the data file ('69dataset.mat') located in the same folder as the script.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tommy/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "/Users/Tommy/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:14: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "### Data import\n",
    "dataset69 = scipy.io.loadmat('69dataset.mat')\n",
    "X = dataset69['X'] # Presented images. 100 images * 784 (28*28) pixels\n",
    "Y = dataset69['Y'] # Measured brain activity. 100 corresponeding to images * 3092 (voxels)\n",
    "X_prior = dataset69['prior'] # Image prior 2000 unshown stimuli * 784 pixels\n",
    "\n",
    "# Data preparation\n",
    "X_norm = (X - np.mean(X, axis=0)) / np.std(X, axis=0) # Normalize every pixel\n",
    "X_norm[np.isnan(X_norm)] = 0 # Because some pixels are always 0, we get nan's for the denominator\n",
    "\n",
    "Y_norm = (Y - np.mean(Y, axis=0)) / np.std(Y, axis=0) # Normalize every voxel\n",
    "Y_norm[np.isnan(Y_norm)] = 0\n",
    "\n",
    "X_prior_norm = (X_prior - np.mean(X_prior, axis=0)) / np.std(X_prior, axis=0) # Normalize every pixel\n",
    "X_prior_norm[np.isnan(X_prior_norm)] = 0\n",
    "\n",
    "X_train = np.concatenate((X_norm[0:40], X_norm[50:90])) # First 40 sixes, last 40 nines\n",
    "X_test = np.concatenate((X_norm[40:50], X_norm[90:100])) # First 10 sixes, last 10 nines\n",
    "\n",
    "Y_train = np.concatenate((Y_norm[0:40], Y_norm[50:90]))\n",
    "Y_test = np.concatenate((Y_norm[40:50], Y_norm[90:100])) #6s [40:50], 9s [90:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining default plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Own function for plot\n",
    "def KAplot(x_estimate, t='', cols=4, rows=10):\n",
    "    X_test_plot = X_test * np.std(X, axis=0) + np.mean(X,axis=0)\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle(t, fontsize=14, fontweight='bold')\n",
    "    rows = 10\n",
    "    cols = 4\n",
    "    index = 3\n",
    "    a = fig.add_subplot(rows, cols, 1)\n",
    "    plt.imshow(np.reshape(X_test_plot[0], [28, 28], order='F'), cmap='binary')  # Image from test data\n",
    "    plt.axis('off')\n",
    "    a.set_title('Original')\n",
    "    a = fig.add_subplot(rows, cols, 2)\n",
    "    plt.imshow(np.reshape(x_estimate[0], [28, 28], order='F'), cmap='binary')  # Order is for getting 6s/9s not mirrors\n",
    "    plt.axis('off')\n",
    "    a.set_title('Reconstructed')\n",
    "\n",
    "    for i in range(1,20):  # Reconstruction of images based on B\n",
    "\n",
    "            fig.add_subplot(rows, cols, index)\n",
    "            plt.imshow(np.reshape(X_test_plot[i], [28, 28], order='F'), cmap='binary')\n",
    "            plt.axis('off')\n",
    "            index += 1\n",
    "            fig.add_subplot(rows, cols, index)\n",
    "            plt.imshow(np.reshape(x_estimate[i], [28, 28], order='F'), cmap='binary')\n",
    "            plt.axis('off')\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "Lambda = 10**-6 # Lambda given\n",
    "B = np.dot(np.dot(np.linalg.inv(np.identity(np.shape(np.dot(Y_train.T,Y_train))[0]) * Lambda + np.dot(Y_train.T,Y_train)), Y_train.T), X_train) # Ridge regression to get B in BX=Y\n",
    "x_estimate = np.dot(B.T, Y_test.T).T\n",
    "\n",
    "X_plot = (x_estimate * np.std(X, axis=0)) + np.mean(X,axis=0) # Undo normalization\n",
    "KAplot(X_plot, t='Traditional approach')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "The covariance is an unnormalized measure for the joint variability in the data. Hence, it represents the amount of information that is shared by certain pixels across the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "B2 = np.dot(np.dot(np.linalg.inv(np.identity(np.shape(np.dot(X_train.T,X_train))[0]) * Lambda + np.dot(X_train.T,X_train)), X_train.T), Y_train) # Ridge regression to get B in BY = X\n",
    "sigma_like = (10**-3) * np.identity(np.shape(Y_train)[1]) # Covariance matrix of likelihood\n",
    "sigma_prior = np.dot(X_prior_norm.T, X_prior_norm) / (np.shape(X_prior_norm)[0] - 1) # Covariance matrix of prior\n",
    "sigma_prior += (10**-6) * np.identity(np.shape(sigma_prior)[0]) # Covariance matrix  of prior, with tip to add 10^-6 to diagonal\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(sigma_prior) # Plot covariance matrix of prior\n",
    "plt.axis('off');\n",
    "plt.suptitle('Sigma matrix of prior', fontsize=14, fontweight='bold')\n",
    "\n",
    "prec_prior = np.linalg.inv(sigma_prior) # Precision of prior\n",
    "prec_like = np.linalg.inv(sigma_like) # Precision of likelihood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "The Bayesian approach seems to work slightly worse than the traditional approach in terms of recognizability of the image reconstruction. This might be due to a bias in the prior. To elucidate, the prior contains two numbers towards the prediction can be biased. Thus, if a nine is predicted, the prior will slightly bias the results to a six and vice verse. This means that ambiguous fMRI data generates a pictures that is resembles the prior, which is a mix of nines and sixes. \n",
    "\n",
    "Improvements using a neural network approach:\n",
    "One of the most prominent weaknesses of the presented approaches is their linearity. A neural network could overcome this problem by employing e.g. non-linear functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "mu_post = np.dot(np.dot(np.dot(np.linalg.inv(np.dot(np.dot(B2,prec_like), B2.T) + prec_prior), B2), prec_like), Y_test.T).T\n",
    "\n",
    "X_plot = mu_post * np.std(X, axis=0) + np.mean(X, axis=0) # Undo normalization\n",
    "KAplot(X_plot, t='Bayesian approach')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
